{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JVM already started\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import csv\n",
    "import os\n",
    "from pprint import pprint\n",
    "from pyrca.analyzers.epsilon_diagnosis import EpsilonDiagnosis, EpsilonDiagnosisConfig\n",
    "import pandas as pd\n",
    "from pyrca.analyzers.bayesian import BayesianNetwork\n",
    "from pyrca.graphs.causal.pc import PC\n",
    "from pyrca.analyzers.rcd import RCD\n",
    "from pyrca.analyzers.ht import HT\n",
    "from pyrca.analyzers.random_walk import RandomWalk, RandomWalkConfig\n",
    "from causallearn.search.ConstraintBased.PC import pc\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import networkx as nx\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SYSTEM = 'sockshop'\n",
    "SYSTEM = 'trainticket'\n",
    "# Define the main directory\n",
    "DATA_FOLDER = Path(f\"../../../vuDevOps/data_collection/{SYSTEM}-data/\")\n",
    "# TRAIN_DATA_FOLDER = f'C:\\scul\\Thesis\\Data Analysis\\{SYSTEM}-data\\normal'\n",
    "# NORMAL_DATA_PATH = os.path.join(DATA_FOLDER, \"normal\")\n",
    "normal_data = pd.read_csv(\"../../AD/ts-normal_data.csv\")\n",
    "anomalous_data = pd.read_csv(\"../../AD/ts-anomalous_data.csv\")\n",
    "K = 3\n",
    "services_to_drop = [\"redis\", \"rabbitmq\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(results, model, trial_path):   \n",
    "\n",
    "    # Extracting node names\n",
    "    nodes_list = [node[0] for node in results['root_cause_nodes']]\n",
    "\n",
    "    # Writing nodes_list to a CSV file\n",
    "    csv_filename = f'{trial_path}\\{model}_results.csv'\n",
    "\n",
    "    with open(csv_filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Root Cause'])\n",
    "        writer.writerows([[node] for node in nodes_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rcd(train_df, test_df, trial_path):\n",
    "    model = RCD(config=RCD.config_class(start_alpha=0.05, k = K, bins= 5, gamma=5, localized=True))\n",
    "    \n",
    "    results = model.find_root_causes(train_df, test_df)\n",
    "    print_results(results.to_dict(), 'rcd', trial_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_circa(train_df, test_df, trial_path):\n",
    "    # Infer causal graph from the training data\n",
    "    cg = pc(data=train_df.to_numpy(), alpha=0.05)\n",
    "    adj = cg.G.graph\n",
    "\n",
    "    adj_matrix = pd.DataFrame(adj, index=train_df.columns, columns=train_df.columns)\n",
    "\n",
    "    model = HT(config=HT.config_class(adj_matrix, aggregator='max', root_cause_top_k=K))\n",
    "    model.train(train_df)\n",
    "    \n",
    "    results = model.find_root_causes(test_df)\n",
    "    print_results(results.to_dict(), 'circa', trial_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "normal_data.dropna(axis=1, inplace=True)\n",
    "anomalous_data.dropna(axis=1, inplace=True)\n",
    "\n",
    "columns_to_drop = [col for col in normal_data.columns if any(substring in col for substring in services_to_drop)]\n",
    "normal_data = normal_data.drop(columns=columns_to_drop)\n",
    "anomalous_data = anomalous_data.drop(columns=columns_to_drop)\n",
    "grouped_anomalous_data = anomalous_data.groupby(['scenario', 'service', 'users', 'repetition'])\n",
    "\n",
    "\n",
    "for (scenario, service, users, repetition), group_df in grouped_anomalous_data:\n",
    "    # Filter the training data from the normal_data DataFrame based on the scenario and users\n",
    "    train_df = normal_data[\n",
    "        (normal_data['scenario'] == scenario) & \n",
    "        (normal_data['users'] == users) & \n",
    "        (normal_data['repetition'] == repetition)\n",
    "    ].copy()\n",
    "\n",
    "    # Filter the test data from the anomalous_data DataFrame for the current scenario, service, users, and repetition\n",
    "    test_df = anomalous_data[\n",
    "            (anomalous_data['scenario'] == scenario) & \n",
    "            (anomalous_data['service'] == service) & \n",
    "            (anomalous_data['users'] == users) & \n",
    "            (anomalous_data['repetition'] == repetition)\n",
    "    ].copy()\n",
    "\n",
    "    trial_path = f\"../results/{SYSTEM}/{scenario}/{service}/{users}/{repetition}\"\n",
    "    os.makedirs(trial_path, exist_ok=True)\n",
    "\n",
    "    train_df = train_df.loc[:, ~(train_df == 0).all()]\n",
    "\n",
    "    # Filter columns that end with _energy, _cpu, _memory_rss\n",
    "    columns_to_keep = train_df.filter(regex='(_energy|_cpu|_memory_rss)$').columns\n",
    "\n",
    "    train_df = train_df[columns_to_keep]\n",
    "    test_df = test_df[columns_to_keep]\n",
    "\n",
    "    print(trial_path)\n",
    "    \n",
    "    run_rcd(train_df, test_df, trial_path)\n",
    "    run_circa(train_df, test_df, trial_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
